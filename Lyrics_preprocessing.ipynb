{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lyrics preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJpgbReJFjQmMe2nvT80YR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlgaSeleznova/ML_toolbox/blob/main/Lyrics_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsrSBxduwzrc"
      },
      "source": [
        "#install modules\n",
        "import sys\n",
        "sys.path.insert(0,'/ML_toolbox/NLP_preprocessing')\n",
        "\n",
        "! pip install langid\n",
        "! pip install NLP_preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R3lYMKss2Sh"
      },
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import re\n",
        "from ML_toolbox.NLP_preprocessing import English_preprocess   #custom module for English preprocessing\n",
        "import langid   # package to identify language of lyrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acpStEDV9E9k",
        "outputId": "cf91b0aa-ba41-47b7-9968-64562c92e8d2"
      },
      "source": [
        "# load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "lyrics = pd.read_parquet('/content/drive/My Drive/ML_toolbox/data/metrolyrics.parquet')\n",
        "lyrics.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49976, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf2I94ZlSPFD",
        "outputId": "8a816426-945c-4028-f0c7-5fb15d07208d"
      },
      "source": [
        "# identify language of the lyric\n",
        "lyrics['language'] = lyrics['lyrics'].apply(lambda x: langid.classify(x)[0])\n",
        "lyrics['language'].value_counts()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    46332\n",
              "es     1381\n",
              "de      668\n",
              "fr      277\n",
              "it      269\n",
              "pt      123\n",
              "sw      118\n",
              "fi       84\n",
              "no       84\n",
              "sv       53\n",
              "Name: language, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGuWrlDnTS-i"
      },
      "source": [
        "Since English posts are 46k out of 49k posts total, and text classification for multiple languages should be prepared separately, we will strat with only English."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGPlut8AS8P4",
        "outputId": "ec80da67-dd2c-4c9c-951b-156c5edaaca6"
      },
      "source": [
        "lyric_en = lyrics[lyrics['language'] == 'en'].copy()\n",
        "lyric_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46332, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pog7zfm7k_iO"
      },
      "source": [
        "Now I will use English preprocessing class for this repository to clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWR3ESVrTH2C"
      },
      "source": [
        "# initialize an object from custom class for English preprocessing\n",
        "cleaner = English_preprocess.English_preprocessing()\n",
        "# create a list of tuples to add custom cleaning with regex\n",
        "to_replace = [(r'[^a-zA-Z]',' '), (r'(\\s+)',' ')]\n",
        "# clean posts with regex\n",
        "lyric_en['lyrics_cleaned'] = lyric_en['lyrics'].apply(lambda x: cleaner.regex_cleaner(x,to_replace))\n",
        "# tokenize lyrics, remove stopwords and join to string.  \n",
        "lyric_en['lyrics_cleaned'] = lyric_en['lyrics_cleaned'].apply(lambda x: ' '.join(cleaner.remove_stopwords(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXtR4DHh7w93"
      },
      "source": [
        "#encode genre names\n",
        "genre_srt_to_int = {'Rock':0, 'Pop':1, 'Hip-Hop':2, 'Metal':3, 'Country':4}\n",
        "lyric_en['genre'] = lyric_en['genre'].replace(genre_srt_to_int)\n",
        "\n",
        "# rename columns to more suitable\n",
        "lyric_en = lyric_en.rename(columns={'lyrics_cleaned':'text','genre':'label'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W_pwq1akjLx"
      },
      "source": [
        "Now posts are cleaned and we can divide data into train, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDDzhnR0Zl4l",
        "outputId": "dd0d576e-e44c-48bb-dd34-37d128859d0f"
      },
      "source": [
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(lyric_en['text'], lyric_en['label'], test_size=1 - train_ratio, random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "print(x_train.shape, x_val.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34749,) (6949,) (4634,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcpHrZK2kxnj"
      },
      "source": [
        "Save datasets to the folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FYJqEudZnOv"
      },
      "source": [
        "def create_datasets(x, y, file_name):\n",
        "    df = pd.concat([x, y], axis=1, ignore_index=False, sort=False)\n",
        "    print('Dataset shape: ',df.shape)\n",
        "    df.to_csv('./data/eng_lyrics/' + file_name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmcJgdMiiGeu"
      },
      "source": [
        "! mkdir data\n",
        "! mkdir data/eng_lyrics/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-zcmfrjaKZN",
        "outputId": "47ee4112-0818-4ca2-90ae-f9a9be28b204"
      },
      "source": [
        "create_datasets(x_train, y_train, 'train.csv')\n",
        "create_datasets(x_val, y_val, 'valid.csv')\n",
        "create_datasets(x_test, y_test, 'test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape:  (34749, 2)\n",
            "Dataset shape:  (6949, 2)\n",
            "Dataset shape:  (4634, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}